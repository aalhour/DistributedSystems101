#+Title: Distributed Systems 101
#+Author: @lvh
#+Email: _@lvh.io

#+OPTIONS: toc:nil reveal_rolling_links:nil num:nil reveal_history:true
#+REVEAL_TRANS: linear
#+REVEAL_THEME: lvh

* Slides

  ~www.lvh.io/DistributedSystems101~

* Introduction

** Who am I?

   #+ATTR_HTML: :style width:80%
   [[./media/lvh.svg]]

** PyCon

   #+ATTR_HTML: :style width:100%
   [[./media/PyCon.png]]

** Rackspace

   #+ATTR_HTML: :style width:50%
   [[./media/rackspace.svg]]

** AutoScale

   #+ATTR_HTML: :style width:90%
   [[./media/threeotters.jpg]]

** AutoScale

   #+ATTR_REVEAL: :frag (roll-in roll-in roll-in roll-in roll-in roll-in)
   * Distributed system
   * Manages distributed systems
   * Running on distributed systems
   * Orchestrating distributed systems
   * At scale

** Why this talk?

   Parallels with Crypto 101

   #+ATTR_REVEAL: :frag (roll-in roll-in roll-in roll-in)
   * Exclusive domain of experts
   * Abstinence-only education
   * Not organized for self-teaching
   * We can't afford not to care

** Disconnect

   Theory ⚡ practice

   #+BEGIN_NOTES
    * Many theoreticians ignore practice
    * Many practitioners ignore theory
   #+END_NOTES

** Distributed Systems 101

   "Just enough" distributed systems

   * to whet your appetite
   * to shoot yourself in the foot

** Goals

   * /Not/ exhaustive, /not/ pedantically correct
   * Give you an idea of what there is & where to look
   * Convince you distributed systems are tricky

     #+BEGIN_NOTES
     The worse I do...
     #+END_NOTES

* Distributed systems?

** What /is/ a distributed system?

   #+BEGIN_QUOTE
   [...] when a machine I've never heard of can cause my program to
   fail.
   #+END_QUOTE

   /-- Leslie Lamport/

** Paradox

   * Why do we use them? Reliability!
   * Experts' primary concern? Failure!

** Fundamental constraints

   1. Information travels at /c/
   2. Components fail

** Fallacies

   1. The network is reliable.
   2. Latency is zero.
   3. Bandwidth is infinite.
   4. The network is secure.
   5. Topology doesn't change.
   6. There is one administrator.
   7. Transport cost is zero.
   8. The network is homogeneous.

** Examples of distributed systems

   #+ATTR_REVEAL: :frag (roll-in roll-in)
   * Basically everything (e.g., your laptop)
     * Speed of light isn't infinite
     * RAM is /all the way over there/
   * Typically:
     * Any system with > 1 machine
     * Connected via network

* Bad news

  Theory and consequences

** CAP theorem

*** Pick any two:

   * Consistency
   * Availability
   * Partition tolerance

*** What does that even mean?

   * C: linearizability (~ local behavior)
   * A: all active nodes answer every query
   * P: resistance to failures

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-base.svg]]

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2.svg]]

*** Can't sacrifice partition tolerance

   #+ATTR_REVEAL: :frag (roll-in roll-in roll-in roll-in)
   * Partition tolerance is failure tolerance
   * Networks, nodes fail all the time
   * Latency happens; indistinguishable
   * P(no failures) < 1 - P(one node works)^N
     * Cascades, Hurst exponent

*** CA (!P)

    "half of the time it doesn't actually work"

*** Pick any two: AP or CP

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2-withp.svg]]

*** CP example: Zookeeper

    Consistent ops that sometimes fail (!A)

*** AP example: Cassandra

    Inconsistent ops (!C) that (usually) succeed

*** Informally

    Let's look at a 5 node cluster

*** 5-node connected cluster

    #+ATTR_HTML: :style width:50%
    [[./media/CAP/Connected.svg]]

*** What happens when stuff fails?

    * I still want to read/write!
    * Idea: (N+1)/2 quorum

*** Some failures

    #+ATTR_HTML: :style width:50%
    [[./media/CAP/Quorum.svg]]

*** Failures are indistinguishable

    #+ATTR_HTML: :style width:50%
    [[./media/CAP/QuorumWithNodeFailures.svg]]

*** Too many failures, no quorum

    #+ATTR_HTML: :style width:50%
    [[./media/CAP/NoQuorum.svg]]

*** Simple quorum isn't enough

    #+ATTR_HTML: :style width:50%
    [[./media/CAP/DoubleQuorum.svg]]

*** Not far-fetched

    Real failures are:

    * partial
    * complex

*** Back to reality

   * CAP's C is linearizability
   * CAP's A is any /op/ on /any/ node
   * These are very strong guarantees!

*** Gradations

   #+ATTR_HTML: :style width:80%
   [[./media/ap-cp.svg]]

*** Trade-offs

    | Availability | Consistency       |
    | Performance  | Ease of reasoning |
    | Scalability  | Transactionality  |

    No universally correct choice!

*** Example of creative sacrifice: ~etcd~

   * Normally: consistency all the way
   * Option of doing inconsistent reads
   * Maybe get some stale data
   * ... but still works under partial failure

** Consistency models

*** One process, one register

    #+ATTR_HTML: :style width:70%
   [[./media/SimpleRegister.svg]]

*** Two processes, one register

   [[./media/SimpleRegisterTwoWriters.svg]]

*** This is how we expect stuff to work

    (We are a spoiled bunch)

*** Information travels at /c/

    #+ATTR_HTML: :style width:50%
    [[./media/SlowRegisters.svg]]

*** Slow stuff can overlap

    #+ATTR_HTML: :style width:90%
   [[./media/SlowOverlap.svg]]

*** Writes don't replicate instantly

    [[./media/SequenceDiagrams/StaleRead.svg]]

    #+BEGIN_NOTES
    One node, two registers
    Write to first one
    Then read from second one
    Write hasn't propagated yet
    #+END_NOTES

*** Writes can get reordered

    [[./media/SequenceDiagrams/ReorderedWrites.svg]]

    #+BEGIN_NOTES
    Two nodes, two registers
    One  writes x to the other register
    Other writes y to the other register
    Registers replicate writes to each other
    Nodes see different orders when reading from their respective register
    One node sees different orders when reading from different registers
    #+END_NOTES

*** All sorts of stuff can happen

    * Multiple registers
    * More semantics
    * More nodes
    * More failure modes

*** Reasoning about the system

    * What can and can't happen?
    * What /can/ happen: consistency model

*** Theoretical consistency models

   #+ATTR_HTML: :style width:85%
   [[./media/ConsistencyModels.svg]]

   #+BEGIN_NOTES
   http://www.bailis.org/papers/hat-vldb2014.pdf
   http://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf
   http://www.allthingsdistributed.com/2008/12/eventually_consistent.html
   #+END_NOTES

*** Serializability

   * ∃ serial execution with the same result
   * /Some/ serial execution: fairly weak
   * No restrictions on which one

*** Example: serializability being weak

    Precondition: /x = 0/

    1. /x ← 0/
    2. /x ← 1/
    3. /x ← 2/

    #+BEGIN_NOTES
    Can be executed in any order
    Therefore any answer is valid
    #+END_NOTES

*** Example: serializability being strong

    Precondition: /x = y = 0/

    1. /y ← 2/, assuming /y = 1/
    2. /x ← 1/, assuming /x = 0/
    3. /y ← x/, assuming /x = 1/

    #+BEGIN_NOTES
    Can only be executed in 1 order
    (2, then 3 because x=1, then 1 because y = 1, net result: x=1 y=2)
    #+END_NOTES

*** Linearizability

   All operations appear to happen instantly

*** Strong serializability

    Linearizable & serializable

*** Your computer is distributed

    Models in "centralized" systems

    * SQL databases
    * Clojure reftypes

*** Twisted vs threads

    In terms of concurrency models

**** Twisted: strongly serializable

     * Event loop with 1 reactor thread
     * Serializable: reactor finds the ordering
     * Linearizable: callbacks run by themselves

**** Threads: no defined model

     * Unladen Swallow tried to figure it out
     * Nothing fancy; whatever your CPU gives you
     * Probably okay (heap + GIL)
     * Correct use of locks?

** Time
*** Global clock model

    #+ATTR_HTML: :style width:60%
    [[./media/Clock/GlobalClock.svg]]

*** Global clock

    * Everyone sees the same clock
    * Access instant, uncertainty 0
    * Can compare different timestamps
    * Mental model: wallclock

*** Local clock model

    #+ATTR_HTML: :style width:60%
    [[./media/Clock/LocalClocks.svg]]

*** Local clocks

    * Each clock is kinda reliable
    * Can't compare with other timestamps
    * Mental model: stopwatch

*** No clock model

    #+ATTR_HTML: :style width:60%
    [[./media/Clock/NoClocks.svg]]

*** Can't have a global clock

    * Can pretend they /almost/ exist
    * Going to be wrong often

*** Example: Google Spanner

    * GPS & atomic clocks
    * "Atomic clocks [...] drift significantly"
    * "uncertainty [...] generally <10ms"

*** Can't have /no/ clock

    * Need time for failure detection
    * FLP result says nothing works

*** Timestamps are often a proxy

    * /Actually/ care about progression, partial order
    * Timestamps don't have to match real-world time

*** Example timeline

    #+ATTR_HTML: :style width:100%
    [[./media/Timeline.svg]]

    Sequential numbers vs real timestamps?

*** Lamport & vector clocks

*** Lamport clocks

    (informally)

    keep a version number of what you've seen

*** Vector clocks

    (informally)

    keep version numbers of what you've seen other nodes see

* Good news

  Stuff you /can/ rely on

** Queues

** Consensus protocols

   Getting computers to agree on things

   #+BEGIN_NOTES
   About as hard as getting humans to agree on things
   #+END_NOTES

*** Examples

   * ZAB (Zookeeper)
   * Paxos* (Chubby)
   * Raft (~etcd~)

** Recipes

   On top of consensus protocols:

   * Locks
   * Barriers
   * Set partitioning
   * ...

*** Set partitioning

    {1, 2, 3, 4, 5}

    #+ATTR_HTML: :style width:60%
    [[./media/SetPartitioning/Happy.svg]]

*** Recovery from failure

    #+ATTR_HTML: :style width:60%
    [[./media/SetPartitioning/Recovery.svg]]

** CRDTs

   Conflict-free replicated data type

*** Problem

    * Read, compute, write back
    * Concurrency: multiple results
    * Conflicts!

*** Solutions?

    * Last write wins? Most writes lose :-(
    * Coordination? Expensive! :-(

*** I want highly available data stores...

    .. but I don't want nonsense data

*** Idea!

    * Describe what you want
    * Describe conflict resolution

*** Specializations

    The C in CRDT can mean:

    * Commutative (CmRDT)
    * Convergent (CvRDT)

*** Commutative RDTs

    * Broadcast operations
    * Merge operation:
      * Commutative: /f(x, y) = f(y, x)/
      * Not idempotent /f(x, y) != f(f(x, y), y)/

*** Example: integers

    * +1, -2, +3, +5, -4: +3
    * Always get same answer:
      * As long as I see all ops /once/
      * Duplicate an op, get wrong answer
      * Order doesn't matter, though

*** Convergent RDTs

    * Broadcast states
    * Merge operation has many properties:
      * Commutative: /f(x, y) = f(y, x)/
      * Idempotent: /f(x, y) = f(f(x, y), y)/
      * Associative: /f(f(x, y), z) = f(x, f(y, z))/
      * Informally: apply lots until done

*** Simple CvRDT conflict resolution

    [[./media/CvRDTMerge.svg]]

*** Complex CvRDT conflict resolution

    It's okay if you see writes more than once!

    [[./media/ComplexCvRDTMerge.svg]]

*** CRDTs in practice: usually CvRDT

    Solve local problem once

    vs

    Solve distributed problem constantly

    #+BEGIN_NOTES
    Local problem: write an algorithm
    Distributed problem: exactly-once delivery
    #+END_NOTES

*** Examples

    * Counters (G, PN)
    * Sets (G, 2P, LWW, PN, OR)
    * Maps (sets of /(k, v)/ tuples)
    * Graphs (using multiple sets)
    * Registers (LWW, MV)
    * Sequences (continuous, RGA)

*** Using CRDTs

    * Designing them is tricky
    * Using them is fairly easy

*** Riak <3

    Flags, registers, counters, sets, maps

* Wrap-up
** Yay, distributed systems!

   * More resilient
   * More performant
   * Make problems tractable

** Argh, distributed systems!

   * Incredibly hard to reason about
   * Huge state space, no repeat scenarios
   * Expensive to operate

** Lots of distributed systems

   * Everything is about tradeoffs
   * Figure out what's right for your app
   * Don't build what's on the shelf

     #+BEGIN_NOTES
     Riak, Zookeeper
     #+END_NOTES

** Why distributed systems?

   Because you're /out of options/.

** Thank you!
* Slides

  ~www.lvh.io/DistributedSystems101~
