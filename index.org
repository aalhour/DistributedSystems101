#+Title: Distributed Systems 101
#+Author: @lvh
#+Email: _@lvh.io

#+OPTIONS: toc:nil reveal_rolling_links:nil num:nil reveal_history:true
#+REVEAL_TRANS: linear
#+REVEAL_THEME: lvh

* Introduction

** Who am I?

   #+ATTR_HTML: :style width:80%
   [[./media/lvh.svg]]

** Rackspace

   #+ATTR_HTML: :style width:90%
   [[./media/rackspace.svg]]

** AutoScale

   #+ATTR_HTML: :style width:90%
   [[./media/threeotters.jpg]]

** AutoScale

   #+ATTR_REVEAL: :frag roll-in
   * Distributed system
   * Manages distributed systems
   * Running on distributed systems
   * Interacting with distributed systems

** Why this talk?

   Parallels with Crypto 101

   #+ATTR_REVEAL: :frag roll-in
   * Field considered exclusive domain of experts
   * Abstinence-only education doesn't work
   * Lots of material, but not organized for self-teaching
   * We can't afford not to care

** Disconnect

    * Many theoreticians ignore practice
    * Many practitioners ignore theory

** Distributed Systems 101

   "Just enough" distributed systems

   #+ATTR_REVEAL: :frag roll-in
   * to whet your appetite
   * to shoot yourself in the foot

* What are distributed systems?

** What /is/ a distributed system?

   A system is distributed if a machine I've never heard of can cause
   my program to fail.

   /Leslie Lamport/

** Paradox

   * Why do we use them? Reliability!
   * Experts' primary concern? Failure!

** Fundamental constraints

   1. Information travels at /c/
   2. Components fail

** Fallacies

   1. The network is reliable.
   2. Latency is zero.
   3. Bandwidth is infinite.
   4. The network is secure.
   5. Topology doesn't change.
   6. There is one administrator.
   7. Transport cost is zero.
   8. The network is homogeneous.

** Examples of distributed systems

   * Basically everything (e.g., your laptop)
     * Speed of light isn't infinite
     * RAM is /all the way over there/
   * Typically:
     * Any system with > 1 machine
     * Connected via network

* Consequences


** CAP theorem

*** Pick any two:

   * Consistency
   * Availability
   * Partition tolerance

*** What does that even mean?

   * Availability: all active nodes answer every query
   * Consistency: linearizability
   * Partition tolerance: failure-resistant

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-base.svg]]

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2.svg]]

*** Can't sacrifice partition tolerance

   * Partition tolerance is failure tolerance
   * Networks, nodes fail all the time
   * Latency happens; indistinguishable
   * P(no failures) < 1 - P(one node works)^N
     * Cascades, Hurst exponent

*** Pick any two: AP or CP

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2-withp.svg]]

*** Examples

   * Zookeeper is CP: consistent ops that sometimes fail
   * Cassandra is AP: inconsistent ops that (usually) succeed

*** Reality

   * CAP's C is linearizability
   * CAP's A is ops on /any/ node
   * These are very strong guarantees!

*** Gradations

   #+ATTR_HTML: :style width:80%
   [[./media/ap-cp.svg]]

*** Reality

   * /Many/ consistency models (real & theoretical)
   * /Many/ levels of availability (0-100%)
   * No reason to sacrifice either outside of failures
   * Systems can choose what to sacrifice (A vs C)

*** Example of creative sacrifice: ~etcd~

   * Normally: consistency all the way
   * Option of doing inconsistent reads
   * Maybe get some stale data
   * ... but still works if the cluster is on fire!

*** What lives in those gray areas?

** Concurrency and consistency models

*** One process, one register

    #+ATTR_HTML: :style width:70%
   [[./media/SimpleRegister.svg]]

*** Two processes, one register

   [[./media/SimpleRegisterTwoWriters.svg]]

*** This is how we expect stuff to work

    We are a spoiled bunch :-)

*** Information travels at /c/

    #+ATTR_HTML: :style width:50%
    [[./media/SlowRegisters.svg]]

*** Slow stuff can overlap

    #+ATTR_HTML: :style width:90%
   [[./media/SlowOverlap.svg]]

*** Concurrency

   Overlapping operations

*** Consistency models

   #+ATTR_HTML: :style width:80%
   [[./media/ConsistencyModels.svg]]

   #+BEGIN_NOTES
   http://www.bailis.org/papers/hat-vldb2014.pdf
   http://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf
   http://www.allthingsdistributed.com/2008/12/eventually_consistent.html
   #+END_NOTES

*** Serializability

   * ∃ serial execution with the same result
   * /Some/ serial execution: fairly weak
     * No restrictions on /which/ serial execution
     * No restrictions on /when/ they execute

*** Example: serializability being weak

    Precondition: /x = 0/

    1. /x ← 0/
    2. /x ← 1/
    3. /x ← 2/

*** Example: serializability being strong

    Precondition: /x = y = 0/

    1. /y ← 2/, assuming /y = 1/
    2. /x ← 1/, assuming /x = 0/
    3. /y ← x/, assuming /x = 1/

*** Compare and set

    Important primitive

*** Linearizability

   All operations appear to happen instantly

*** Strong serializability

   * Linearizable & serializable
   * There is a serial execution ...
   * ... and that execution is unique & matches wallclock time (???)

*** Your computer is distributed

    Models also exist in "centralized" systems

    * SQL databases
    * Clojure's reference types

*** Twisted vs threads

    * Twisted: strongly serializable
      * Event loop with 1 reactor thread
      * Serializable: reactor finds the ordering
      * Linearizable: callbacks run by themselves
    * Threads: usually more like read uncommitted
      * Many Python opcodes are atomic
      * Correct use of locks?


** FLP

** Wallclocks

* Tools and components

** Queues

** Consensus protocols

*** Examples

   * ZAB (used in Zookeeper)
   * Paxos (think 2PC, but distributed)
   * Raft (used in ~etcd~)

** Consensus protocol recipes

   * Set partitioning
   * Consistent counters
   * ...

** CRDTs

** Previously: CAP

    * Presented as trade-off: C versus A
    * Doesn't explain what we can do /on/ that line
    * CRDTs: wonderful modern example of what we can do

* Wrap-up
** Yay, distributed systems!

   * More resilient
   * More performant
   * Make problems tractable

** Argh, distributed systems!

   * Incredibly hard to reason about
   * Huge state space, no repeat scenarios
   * Expensive to operate

** Why distributed systems?

   Because you're /out of options/.

** Questions?
