#+Title: Distributed Systems 101
#+Author: @lvh
#+Email: _@lvh.io

#+OPTIONS: toc:nil reveal_rolling_links:nil num:nil reveal_history:true
#+REVEAL_TRANS: linear
#+REVEAL_THEME: lvh

* Introduction

** Who am I?

   #+ATTR_HTML: :style width:80%
   [[./media/lvh.svg]]

** Rackspace

   #+ATTR_HTML: :style width:90%
   [[./media/rackspace.svg]]

** AutoScale

   #+ATTR_HTML: :style width:90%
   [[./media/threeotters.jpg]]

** AutoScale

   #+ATTR_REVEAL: :frag roll-in
   * Distributed system
   * Manages distributed systems
   * Running on distributed systems
   * Interacting with distributed systems

** Why this talk?

   Parallels with Crypto 101

   #+ATTR_REVEAL: :frag roll-in
   * Field considered exclusive domain of experts
   * Abstinence-only education doesn't work
   * Lots of material, but not organized for self-teaching
   * We can't afford not to care

** Disconnect

    * Many theoreticians ignore practice
    * Many practitioners ignore theory

** Distributed Systems 101

   "Just enough" distributed systems

   #+ATTR_REVEAL: :frag roll-in
   * to whet your appetite
   * to shoot yourself in the foot

* Distributed systems and concurrency

** What /is/ a distributed system?

   A system is distributed if a machine I've never heard of can cause
   my program to fail.

   /Leslie Lamport/

** Paradox

   * Why do we use them? Reliability!
   * Experts' primary concern? Failure!

** Fundamental constraints

   1. Information travels at /c/
   2. Components fail

** Fallacies

   1. The network is reliable.
   2. Latency is zero.
   3. Bandwidth is infinite.
   4. The network is secure.
   5. Topology doesn't change.
   6. There is one administrator.
   7. Transport cost is zero.
   8. The network is homogeneous.

** Examples of distributed systems

   * Basically everything (e.g., your laptop)
     * Speed of light isn't infinite
     * RAM is /all the way over there/
   * Typically:
     * Any system with > 1 machine
     * Connected via network

* Consequences

** Concurrency

*** One process, one register

    #+ATTR_HTML: :style width:70%
   [[./media/SimpleRegister.svg]]

*** Two processes, one register

   [[./media/SimpleRegisterTwoWriters.svg]]

*** Information travels at /c/

    #+ATTR_HTML: :style width:50%
   [[./media/SlowRegisters.svg]]

*** Concurrency

   Overlapping operations

** Consistency models

   #+ATTR_HTML: :style width:80%
   [[./media/ConsistencyModels.svg]]

   #+BEGIN_NOTES
   http://www.bailis.org/papers/hat-vldb2014.pdf
   http://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf
   http://www.allthingsdistributed.com/2008/12/eventually_consistent.html
   #+END_NOTES

*** Serializability

   * âˆƒ serial execution with the same result
   * /Some/ serial execution: fairly weak
     * No restrictions on /which/ serial execution
     * No restrictions on /when/ they execute

*** Linearizability

   All operations appear to happen instantly

*** Strong serializability

   * Linearizable & serializable
   * There is a serial execution ...
   * ... and that execution is unique & matches wallclock time (???)

*** Your computer is distributed

    * Models also exist in "centralized" systems
    * SQL databases support many of these models
    * Clojure's reference types

*** In Python: Twisted, asyncyio... vs threads

    * Twisted: strongly serializable
      * Event loop with 1 reactor thread
      * Serializable: reactor finds the ordering
      * Linearizable: callbacks run by themselves
    * Threads: usually more like read uncommitted
      * Many Python opcodes are atomic
      * Correct use of locks?

** CAP
*** Pick any two:

   * Consistency
   * Availability
   * Partition tolerance

*** What does that even mean?

   * Availability, n.: all active nodes answer every query
   * Consistency:, n.: linearizability
   * Partition tolerance, p.: failure-resistant

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-base.svg]]

*** Pick any two

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2.svg]]

*** Can't sacrifice partition tolerance

   * Partition tolerance is failure tolerance
   * Networks, nodes fail all the time
   * Latency happens; indistinguishable
   * P(no failures) < 1 - P(one node works)^N
     * Cascades, Hurst exponent

*** Pick any two: AP or CP

   #+ATTR_HTML: :style width:50%
   [[./media/cap-venn-any2-withp.svg]]

*** Examples

   * Zookeeper is CP: consistent ops that sometimes fail
   * Cassandra is AP: inconsistent ops that (usually) succeed

*** Reality

   * CAP's C is linearizability
   * CAP's A is ops on /any/ node
   * These are very strong guarantees!

*** Gradations

   #+ATTR_HTML: :style width:80%
   [[./media/ap-cp.svg]]

*** Reality

   * There are /many/ consistency models (real & theoretical)
   * There are /many/ levels of availability (0-100%)
   * No reason to sacrifice either outside of failures
   * Systems can sacrifice many things during failures

*** Example of creative sacrifice: ~etcd~

   * Normally: consistency all the way
   * Option of doing inconsistent reads
   * Maybe get some stale data
   * ... but still works if the cluster is on fire!


* Impossibility results

** FLP

** Wallclocks


* Tools and components

  (High and low level)

** Queues

** Consensus protocols

*** Examples

   * ZAB (used in Zookeeper)
   * Paxos (think 2PC, but distributed)
   * Raft (used in ~etcd~)

** Consensus protocol recipes

   * Set partitioning
   * Consistent counters
   * ...

** CRDTs

** Previously: CAP

    * Presented as trade-off: C versus A
    * Doesn't explain what we can do /on/ that line
    * CRDTs: wonderful modern example of what we can do

* Wrap-up
** Yay, distributed systems!

   * More resilient
   * More performant
   * Make problems tractable

** Argh, distributed systems!

   * Incredibly hard to reason about
   * Huge state space, no repeat scenarios
   * Expensive to operate

** Why distributed systems?

   Because you're /out of options/.

** Questions?
